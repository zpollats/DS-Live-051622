{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our animation skills to illustrate gradient descent. This is that celebrated machine learning algorithm that finds the minimum of a cost function by using the (negative) gradient of that function iteratively to improve guesses as to the optimal parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a Regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "x = np.random.rand(100, 1)\n",
    "y = [2*x_i + 10 + 2*np.random.rand() for x_i in x];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(x, y)\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustrate Relative Positions of Lines and Positions in Parameter Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll build a function that will show, for *two* inputs each of slope and intercept, where the associated line is relative to our data points and also where we are on the (3-d) cost curve in parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse(m, x, b, y):\n",
    "    \"\"\"\n",
    "    This function returns the sum of squared errors for\n",
    "    a target y and a linear estimate mx + b.\n",
    "    \"\"\"\n",
    "    return len(x) * mean_squared_error(y, m*x + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function will make use of [`matplotlib` colormaps](https://matplotlib.org/3.5.0/tutorials/colors/colormaps.html) to plot the 3-d cost curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line_and_point_in_beta_space(slope1, const1, slope2, const2, x, y,\n",
    "                                     data_color='k', line_color='m',\n",
    "                                     cmap='binary', spot_color='r'):\n",
    "    \"\"\"\n",
    "    This function will plot the lines through a set of data points\n",
    "    and the positions in \"beta space\" for *two* inputs each of\n",
    "    slope and y-intercept for a simple linear regression problem.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from matplotlib import pyplot as plt\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    ax0.scatter(x, y, c=data_color)\n",
    "    ax0.plot(x, slope1*x + const1, c=line_color)\n",
    "    \n",
    "    ax1.scatter(x, y, c=data_color)\n",
    "    ax1.plot(x, slope2*x + const2, c=line_color)\n",
    "    plt.show()\n",
    "    \n",
    "    model = LinearRegression().fit(x, y)\n",
    "    true_slope = model.coef_[0]\n",
    "    true_const = model.intercept_\n",
    "    \n",
    "    # This section of code just insures that the plot will\n",
    "    # include the true slope and intercept values.\n",
    "    if slope1 < true_slope:\n",
    "        ms1 = np.linspace(slope1, 2*true_slope - slope1, 100)\n",
    "    else:\n",
    "        ms1 = np.linspace(2*true_slope - slope1, slope1, 100)\n",
    "    \n",
    "    if const1 < true_const:\n",
    "        bs1 = np.linspace(const1, 2*true_const - const1, 100)\n",
    "    else:\n",
    "        bs1 = np.linspace(2*true_const - const1, const1, 100)\n",
    "        \n",
    "    if slope2 < true_slope:\n",
    "        ms2 = np.linspace(slope2, 2*true_slope - slope2, 100)\n",
    "    else:\n",
    "        ms2 = np.linspace(2*true_slope - slope2, slope2, 100)\n",
    "    \n",
    "    if const2 < true_const:\n",
    "        bs2 = np.linspace(const2, 2*true_const - const2, 100)\n",
    "    else:\n",
    "        bs2 = np.linspace(2*true_const - const2, const2, 100)\n",
    "\n",
    "    X_grid1, Y_grid1 = np.meshgrid(ms1, bs1)\n",
    "\n",
    "    Z1 = np.array([[sse(m, x, b, y) for m in ms1] for b in bs1])\n",
    "    \n",
    "    X_grid2, Y_grid2 = np.meshgrid(ms2, bs2)\n",
    "    \n",
    "    Z2 = np.array([[sse(m, x, b, y) for m in ms2] for b in bs2])\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax2 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    ax2.contour3D(X_grid1, Y_grid1, Z1, 200, cmap=cmap)\n",
    "    ax2.set_xlabel('slope')\n",
    "    ax2.set_ylabel('y-intercept')\n",
    "    ax2.scatter(slope1, const1, sse(slope1, x, const1, y),\n",
    "               c=spot_color, marker='o', s=200)\n",
    "    \n",
    "    ax3 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    ax3.contour3D(X_grid2, Y_grid2, Z2, 200, cmap=cmap)\n",
    "    ax3.set_xlabel('slope')\n",
    "    ax3.set_ylabel('y-intercept')\n",
    "    ax3.scatter(slope2, const2, sse(slope2, x, const2, y),\n",
    "               c=spot_color, marker='o', s=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_line_and_point_in_beta_space(4, 8, 3, 10, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Animated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we want to show how guesses *improve* using gradient descent, then we'll need to code up that algorithm. First we'll code up the partial derivatives of the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_deriv(a, b, x_i, y_i, respect_to):\n",
    "    \"\"\"\n",
    "    Get the partial derivative for cost function with respect to slope (a) \n",
    "    or intercept (b).\n",
    "    \"\"\"\n",
    "    if respect_to == 'b': # intercept\n",
    "        return (y_i - (a * x_i + b))\n",
    "    elif respect_to == 'a': # slope\n",
    "        return (x_i * (y_i - (a * x_i + b)))\n",
    "    else:\n",
    "        print('Choose either respect_to: a or b ')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll express one iteration of the algorithm: Take an initial guess and then improve them by going in the opposite direction of the gradient at that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(a, b, x, y, learning_rate):\n",
    "    \"\"\"\n",
    "    This function returns a new slope-intercept pair, calculated\n",
    "    using gradient descent, for input data and an initial pair of\n",
    "    guesses.\n",
    "    \"\"\"\n",
    "    db = 0\n",
    "    da = 0 \n",
    "    # For each data point, update the derivative for the slope & intercept\n",
    "    N = len(x)\n",
    "    for i in range(N):\n",
    "        \n",
    "        # Partial derivatives of loss/cost function with respect to b & a\n",
    "        # Here's where we're taking our averages. Notice that we're leaving\n",
    "        # off the factors of 2.\n",
    "        db +=  -(1/N) * partial_deriv(a, b, x[i], y[i], respect_to='b')\n",
    "        da +=  -(1/N) * partial_deriv(a, b, x[i], y[i], respect_to='a')\n",
    "        \n",
    "    # Adjust the slope & intercept by the gradient\n",
    "    new_b = b - (learning_rate * db)\n",
    "    new_a = a - (learning_rate * da)\n",
    "    \n",
    "    return new_a, new_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_desc_illus(slope_init, const_init, x, y, n_iter=100, alpha=1,\n",
    "                   line_color='c', data_color='k'):\n",
    "    \"\"\"\n",
    "    This function illustrates gradient descent by repeatedly applying\n",
    "    the step_gradient() function and visualizing the results.\n",
    "    \"\"\"\n",
    "    new_slope, new_const = slope_init, const_init\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(x, y, c=data_color)\n",
    "    plt.plot(x, slope_init*x + const_init)\n",
    "    for _ in range(n_iter):\n",
    "        clear_output(wait=True)\n",
    "        guess = {\n",
    "            'slope': new_slope,\n",
    "            'intercept': new_const\n",
    "        }\n",
    "\n",
    "        beta_1, beta_0 = step_gradient(guess['slope'],\n",
    "                                       guess['intercept'],\n",
    "                                       x, y, learning_rate=alpha)\n",
    "        new_slope = beta_1\n",
    "        new_const = beta_0\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(x, y, c=data_color)\n",
    "        plt.plot(x, new_slope*x + new_const, c=line_color)\n",
    "        plt.show()\n",
    "    \n",
    "    return new_slope[0], new_const[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_desc_illus(3, 8, x, y, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_desc_illus(3, 12, x, y, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_desc_illus(10, -5, x, y, line_color='m', data_color='brown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution in Slope-Intercept Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now get this animation working for our points in beta space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_desc_illus_betas(slope_init, const_init, x, y, n_iter=100, alpha=1,\n",
    "                          color='k', figsize=(8, 8), cmap='binary'):\n",
    "    \"\"\"\n",
    "    This function illustrates gradient descent by repeatedly applying\n",
    "    the step_gradient() function and visualizing the results in\n",
    "    parameter space.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from matplotlib import pyplot as plt\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "    model = LinearRegression().fit(x, y)\n",
    "    true_slope = model.coef_[0]\n",
    "    true_const = model.intercept_\n",
    "    \n",
    "    if slope_init < true_slope:\n",
    "        ms = np.linspace(slope_init, 2*true_slope - slope_init, 100)\n",
    "    else:\n",
    "        ms = np.linspace(2*true_slope - slope_init, slope_init, 100)\n",
    "    \n",
    "    if const_init < true_const:\n",
    "        bs = np.linspace(const_init, 2*true_const - const_init, 100)\n",
    "    else:\n",
    "        bs = np.linspace(2*true_const - const_init, const_init, 100)\n",
    "\n",
    "    X_grid, Y_grid = np.meshgrid(ms, bs)\n",
    "\n",
    "    Z = np.array([[sse(m, x, b, y) for m in ms] for b in bs])\n",
    "    new_slope, new_const = slope_init, const_init\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.contour3D(X_grid, Y_grid, Z, 200, cmap=cmap)\n",
    "    ax.set_xlabel('slope')\n",
    "    ax.set_ylabel('y-intercept')\n",
    "    ax.set_zlabel('sum of squared errors')\n",
    "    ax.scatter(new_slope, new_const, sse(new_slope, x, new_const, y),\n",
    "                   c=color, marker='o', s=200)\n",
    "    plt.title('Error as a function of slope and y-intercept');\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        clear_output(wait=True)\n",
    "        guess = {\n",
    "            'slope': new_slope,\n",
    "            'intercept': new_const\n",
    "        }\n",
    "\n",
    "        beta_1, beta_0 = step_gradient(guess['slope'],\n",
    "                                       guess['intercept'],\n",
    "                                       x, y, learning_rate=alpha)\n",
    "        new_slope = beta_1\n",
    "        new_const = beta_0\n",
    "        plt.figure(figsize=figsize)\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.contour3D(X_grid, Y_grid, Z, 200, cmap=cmap)\n",
    "        ax.set_xlabel('slope')\n",
    "        ax.set_ylabel('y-intercept')\n",
    "        ax.scatter(beta_1, beta_0, sse(beta_1, x, beta_0, y),\n",
    "                   c=color, marker='o', s=200)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_desc_illus_betas(5, 5, x, y, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_desc_illus_betas(10, 2, x, y, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_desc_illus_betas(-8, 15, x, y, n_iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_desc_illus_betas(-12, -20, x, y, color='r', alpha=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
